{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>medical_specialty</th>\n",
       "      <th>transcription</th>\n",
       "      <th>medical_label</th>\n",
       "      <th>word2vec_embed</th>\n",
       "      <th>fasttext_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>cardiovascular_pulmonary</td>\n",
       "      <td>d m mode leave atrial enlargement left atrial ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-3.9130253e-01  1.6925055e+00 -9.7060895e-01 ...</td>\n",
       "      <td>__label__cardiovascular_pulmonary d m mode lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>cardiovascular_pulmonary</td>\n",
       "      <td>left ventricular cavity size wall thickness ap...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-5.44876158e-01  1.30335271e+00 -1.53507555e+...</td>\n",
       "      <td>__label__cardiovascular_pulmonary left ventric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>cardiovascular_pulmonary</td>\n",
       "      <td>d echocardiogram multiple view heart great ves...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.40531728  0.8317133  -1.0865903   0.296900...</td>\n",
       "      <td>__label__cardiovascular_pulmonary d echocardio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>cardiovascular_pulmonary</td>\n",
       "      <td>description normal cardiac chamber size normal...</td>\n",
       "      <td>0</td>\n",
       "      <td>[-0.3478441   0.9546592  -1.0535976   1.201930...</td>\n",
       "      <td>__label__cardiovascular_pulmonary description ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>cardiovascular_pulmonary</td>\n",
       "      <td>d study mild aortic stenosis widely calcify mi...</td>\n",
       "      <td>0</td>\n",
       "      <td>[ 0.27329454  1.1477208  -0.88355297  1.073992...</td>\n",
       "      <td>__label__cardiovascular_pulmonary d study mild...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0         medical_specialty  \\\n",
       "0           3  cardiovascular_pulmonary   \n",
       "1           4  cardiovascular_pulmonary   \n",
       "2           7  cardiovascular_pulmonary   \n",
       "3           9  cardiovascular_pulmonary   \n",
       "4          11  cardiovascular_pulmonary   \n",
       "\n",
       "                                       transcription  medical_label  \\\n",
       "0  d m mode leave atrial enlargement left atrial ...              0   \n",
       "1  left ventricular cavity size wall thickness ap...              0   \n",
       "2  d echocardiogram multiple view heart great ves...              0   \n",
       "3  description normal cardiac chamber size normal...              0   \n",
       "4  d study mild aortic stenosis widely calcify mi...              0   \n",
       "\n",
       "                                      word2vec_embed  \\\n",
       "0  [-3.9130253e-01  1.6925055e+00 -9.7060895e-01 ...   \n",
       "1  [-5.44876158e-01  1.30335271e+00 -1.53507555e+...   \n",
       "2  [-0.40531728  0.8317133  -1.0865903   0.296900...   \n",
       "3  [-0.3478441   0.9546592  -1.0535976   1.201930...   \n",
       "4  [ 0.27329454  1.1477208  -0.88355297  1.073992...   \n",
       "\n",
       "                                      fasttext_label  \n",
       "0  __label__cardiovascular_pulmonary d m mode lea...  \n",
       "1  __label__cardiovascular_pulmonary left ventric...  \n",
       "2  __label__cardiovascular_pulmonary d echocardio...  \n",
       "3  __label__cardiovascular_pulmonary description ...  \n",
       "4  __label__cardiovascular_pulmonary d study mild...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.read_csv('data/medical_new.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def help(dataframe, vectorizer, model):\n",
    "    x_train, x_test, y_train, y_test= train_test_split(dataframe.transcription, dataframe.medical_label, stratify= dataframe.medical_label, test_size= 0.2, random_state= 5354)\n",
    "    \n",
    "    model= Pipeline([\n",
    "        ('vectorizer', vectorizer),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    model.fit(x_train, y_train)\n",
    "    print(model.score(x_test, y_test))\n",
    "\n",
    "    y_pred= model.predict(x_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNT VECTORIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6916666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.84      0.81        56\n",
      "           1       0.97      0.87      0.92        39\n",
      "           2       0.49      0.56      0.52        34\n",
      "           3       0.87      0.75      0.81        61\n",
      "           4       0.38      0.40      0.39        50\n",
      "\n",
      "    accuracy                           0.69       240\n",
      "   macro avg       0.70      0.68      0.69       240\n",
      "weighted avg       0.71      0.69      0.70       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data, CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COUNT VECTORIZER WITH BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6375\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77        56\n",
      "           1       0.94      0.79      0.86        39\n",
      "           2       0.44      0.47      0.46        34\n",
      "           3       0.77      0.80      0.78        61\n",
      "           4       0.26      0.24      0.25        50\n",
      "\n",
      "    accuracy                           0.64       240\n",
      "   macro avg       0.63      0.62      0.62       240\n",
      "weighted avg       0.64      0.64      0.64       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data, CountVectorizer(ngram_range= (1, 2)), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6291666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.80      0.77        56\n",
      "           1       0.94      0.79      0.86        39\n",
      "           2       0.42      0.44      0.43        34\n",
      "           3       0.77      0.80      0.78        61\n",
      "           4       0.24      0.22      0.23        50\n",
      "\n",
      "    accuracy                           0.63       240\n",
      "   macro avg       0.62      0.61      0.61       240\n",
      "weighted avg       0.63      0.63      0.63       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data, CountVectorizer(ngram_range= (1, 3)), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF VECTORIZER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6416666666666667\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.86      0.77        56\n",
      "           1       0.96      0.69      0.81        39\n",
      "           2       0.43      0.26      0.33        34\n",
      "           3       0.69      0.89      0.78        61\n",
      "           4       0.36      0.32      0.34        50\n",
      "\n",
      "    accuracy                           0.64       240\n",
      "   macro avg       0.63      0.60      0.60       240\n",
      "weighted avg       0.63      0.64      0.63       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data, TfidfVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF VECTORIZER WITH BOW"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### bigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5875\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.80      0.74        56\n",
      "           1       0.96      0.62      0.75        39\n",
      "           2       0.31      0.15      0.20        34\n",
      "           3       0.62      0.87      0.73        61\n",
      "           4       0.29      0.28      0.28        50\n",
      "\n",
      "    accuracy                           0.59       240\n",
      "   macro avg       0.57      0.54      0.54       240\n",
      "weighted avg       0.58      0.59      0.57       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data, TfidfVectorizer(ngram_range= (1, 2)), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### trigram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5625\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.79      0.74        56\n",
      "           1       0.96      0.59      0.73        39\n",
      "           2       0.21      0.09      0.12        34\n",
      "           3       0.61      0.84      0.70        61\n",
      "           4       0.25      0.28      0.27        50\n",
      "\n",
      "    accuracy                           0.56       240\n",
      "   macro avg       0.55      0.52      0.51       240\n",
      "weighted avg       0.56      0.56      0.54       240\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(data, TfidfVectorizer(ngram_range= (1, 3)), MultinomialNB())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SMOTE ANALYSIS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smote(dataframe, vectorizer, model):\n",
    "\n",
    "    #features and target\n",
    "    x= vectorizer.fit_transform(dataframe['transcription'])\n",
    "    y= dataframe['medical_label']\n",
    "\n",
    "    #smote apply\n",
    "    smote = SMOTE()\n",
    "    X_sm, y_sm = smote.fit_resample(x,y)\n",
    "    \n",
    "    #train test split\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X_sm, y_sm, test_size=0.2, random_state=5, stratify=y_sm)\n",
    "    model.fit(x_train, y_train)\n",
    "    print(model.score(x_test, y_test)) \n",
    "    \n",
    "    y_pred= model.predict(x_test)\n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7557755775577558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.87      0.79        60\n",
      "           1       0.89      0.90      0.89        61\n",
      "           2       0.74      0.84      0.78        61\n",
      "           3       0.79      0.87      0.83        61\n",
      "           4       0.53      0.30      0.38        60\n",
      "\n",
      "    accuracy                           0.76       303\n",
      "   macro avg       0.74      0.75      0.74       303\n",
      "weighted avg       0.74      0.76      0.74       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tfidf BOW\n",
    "smote(data, TfidfVectorizer(ngram_range=(1, 2)), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7557755775577558\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.88      0.81        60\n",
      "           1       0.90      0.90      0.90        61\n",
      "           2       0.73      0.75      0.74        61\n",
      "           3       0.77      0.90      0.83        61\n",
      "           4       0.54      0.33      0.41        60\n",
      "\n",
      "    accuracy                           0.76       303\n",
      "   macro avg       0.74      0.75      0.74       303\n",
      "weighted avg       0.74      0.76      0.74       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#tfidf\n",
    "smote(data, TfidfVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7029702970297029\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.87      0.78        60\n",
      "           1       0.94      0.82      0.88        61\n",
      "           2       0.67      0.66      0.66        61\n",
      "           3       0.83      0.87      0.85        61\n",
      "           4       0.35      0.30      0.32        60\n",
      "\n",
      "    accuracy                           0.70       303\n",
      "   macro avg       0.70      0.70      0.70       303\n",
      "weighted avg       0.70      0.70      0.70       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#countvectorizer\n",
    "smote(data, CountVectorizer(), MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6798679867986799\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.80      0.74        60\n",
      "           1       0.93      0.84      0.88        61\n",
      "           2       0.68      0.59      0.63        61\n",
      "           3       0.77      0.87      0.82        61\n",
      "           4       0.32      0.30      0.31        60\n",
      "\n",
      "    accuracy                           0.68       303\n",
      "   macro avg       0.68      0.68      0.68       303\n",
      "weighted avg       0.68      0.68      0.68       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#countvectorizer with bow\n",
    "smote(data, CountVectorizer(ngram_range=(1,2)), MultinomialNB())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
